# ğŸ§¬ AG-vs-ACO-CBGA  
**Comparison and Hyperparameter Tuning of GA, ACO, and Chuâ€“Beasley GA (CBGA) for TSPLIB TSP Instances**

> Modular OOP implementation with multi-seed statistical evaluation and convergence analysis.

---

## ğŸš€ Workshop Overview  
### Comparison and Tuning of GA vs ACO for the TSP (TSPLIB)  
### ğŸ”¥ PLUS Extension: Chuâ€“Beasley Genetic Algorithm (CBGA)

This project presents a modular, object-oriented implementation of metaheuristic algorithms for solving the **Traveling Salesman Problem (TSP)** using benchmark instances from **TSPLIB**.

---

## ğŸ§  Algorithms Implemented

The study includes the following metaheuristics:

- **Genetic Algorithm (GA)**
- **Ant Colony Optimization (ACO)**
- **Chuâ€“Beasley Genetic Algorithm (CBGA)**
- **Random Search** *(baseline reference)*

---

## ğŸ”¬ Research Objectives

- Compare the performance of GA and ACO on multiple TSPLIB instances  
- Extend the comparison by incorporating the Chuâ€“Beasley GA (CBGA)  
- Perform hyperparameter tuning using Grid Search  
- Evaluate robustness through multi-seed statistical analysis  
- Analyze convergence behavior and variability across runs  

---

## ğŸ“Š Experimental Methodology

### ğŸ” Multi-Seed Evaluation  
Each experiment is executed with **5 independent runs (seeds 42â€“46)** to ensure statistical robustness.

### ğŸ“ˆ Reported Metrics

The following statistical indicators are computed:

- **Mean Â± Standard Deviation**
- **Best Global Distance**
- **Worst Global Distance**
- **Average Execution Time**
- **Mean GAP (%)** relative to known optimal solutions
- **Convergence Curves (mean Â± std)**
- **Boxplot Distribution Analysis**
- **Best Tour Visualization**

---

## ğŸ—ï¸ System Architecture

The project follows a clean **Object-Oriented Programming (OOP)** modular structure:

```bash
tsp_project/
â”‚
â”œâ”€â”€ core/              # Problem abstraction and experiment runner
â”œâ”€â”€ algorithms/        # GA, ACO, CBGA, Random Search
â”œâ”€â”€ tuning/            # Grid Search module
â”œâ”€â”€ visualization/     # Convergence and statistical plots
â”œâ”€â”€ config.py          # Instances and known optima
â””â”€â”€ main.py            # Interactive execution menu
```


### Architectural Principles

- Separation of concerns  
- Algorithm abstraction via base class  
- Reproducible experimental framework  
- Extensibility for future metaheuristics  

---

## âš™ï¸ Key Features

- Fully modular OOP design  
- Multi-instance evaluation (TSPLIB)  
- Automated statistical reporting  
- Convergence curve visualization (mean Â± std)  
- Hyperparameter tuning via Grid Search  
- Robust multi-seed experimentation  
- Interactive execution menu  

---

## ğŸ¯ Academic Focus

This project emphasizes proper experimental methodology in stochastic metaheuristics, including:

- Statistical validation  
- Robustness analysis  
- Performance comparison  
- Reproducibility of results  

The implementation aims to follow good research practices for computational experimentation in metaheuristic optimization.

---

## ğŸ“ Additional Materials

The repository includes complementary academic material:

- ğŸ“„ **Technical Report** containing detailed experimental results and statistical analysis  
- ğŸ““ **Google Colab Notebook** for easy execution and reproducibility  
- ğŸ“Š **Brief Presentation** summarizing methodology, comparison, and key findings  

These materials provide a complete overview of the experimental framework, results interpretation, and conclusions derived from the comparative study.
